package com.peoplenet.rerun.replay.kafka

import groovy.transform.CompileStatic
import groovy.util.logging.Slf4j
import kafka.api.FetchRequest
import kafka.api.FetchRequestBuilder
import kafka.common.ErrorMapping
import kafka.javaapi.FetchResponse
import kafka.javaapi.consumer.SimpleConsumer
import kafka.message.MessageAndOffset
import org.apache.kafka.common.errors.OffsetOutOfRangeException

import java.nio.ByteBuffer

/**
 * A stream of messages generated by the RangedConsumer
 */
@Slf4j
@CompileStatic
class RangedStream implements MessageStream {
    private KafkaConnectionFactory cnxnFactory
    private OffsetRange offsetRange
    private PartitionInformation partitionInfo
    private Long currentOffset
    private Long readOffset

    RangedStream(KafkaConnectionFactory cnxnFactory, OffsetRange offsetRange, PartitionInformation partitionInfo) {
        this.cnxnFactory = cnxnFactory
        this.offsetRange = offsetRange
        this.partitionInfo = partitionInfo
    }

    @Override
    void beginStreaming(Closure closure) {
        boolean complete = false
        readOffset = offsetRange.start

        while(!complete) {
            try {
                innerStreaming(closure)
                complete = true
            } catch (LeaderMayNotBeLeaderException e) {
                log.warn("Leader change detected, attempting to find new leader. " +
                        "topic:partition -> '${partitionInfo.topic}:${partitionInfo.partitionId}'")

                partitionInfo = cnxnFactory.refreshPartitionInformation(partitionInfo)

                if(!partitionInfo) {
                    log.error 'Failed to update leader information'
                    throw e
                }
            }
        }
    }

    private void innerStreaming(Closure closure) {
        cnxnFactory.withSimpleConsumer(partitionInfo.leader) { SimpleConsumer consumer ->
            readOffset = offsetRange.start

            while (!offsetRange.after(readOffset)) {
                FetchRequest req = new FetchRequestBuilder()
                        .clientId(cnxnFactory.clientId)
                        .addFetch(partitionInfo.topic, partitionInfo.partitionId, readOffset, 100000)
                        .build()

                FetchResponse fetchResponse = consumer.fetch(req)

                if (fetchResponse.hasError()) {
                    handleError(fetchResponse)
                } else {
                    fetchResponse.messageSet(partitionInfo.topic, partitionInfo.partitionId).each { MessageAndOffset mao ->
                        currentOffset = mao.offset()

                        if (offsetRange.includesOffset(currentOffset)) {

                            readOffset = mao.nextOffset()
                            ByteBuffer payload = mao.message().payload()

                            byte[] bytes = new byte[payload.limit()]
                            payload.get(bytes)

                            KafkaMessage message = new KafkaMessage(
                                    payload: bytes,
                                    topic: partitionInfo.topic,
                                    partitionId: partitionInfo.partitionId,
                                    offset: currentOffset
                            )


                            closure.call(message)
                        }
                    }
                }
            }
        }
    }

    private void handleError(FetchResponse fetchResponse) {
        short code = fetchResponse.errorCode(partitionInfo.topic, partitionInfo.partitionId)

        log.error "Error while fetching data for '${partitionInfo.topic}' from " +
                         "'${partitionInfo.leader.host}:${partitionInfo.leader.port}', code: ${code}"

        if (code == ErrorMapping.OffsetOutOfRangeCode()) {
            throw new OffsetOutOfRangeException(
                "OFFSET OUT OF RANGE: '${offsetRange.start}', topic:  '${partitionInfo.topic}', " +
                        "partition: '${partitionInfo.partitionId}'")
        } else {
            throw new LeaderMayNotBeLeaderException(
                    oldLeader: new BrokerAddress(partitionInfo.leader.host, partitionInfo.leader.port))
        }

    }
}
